# -*- coding: utf-8 -*-
"""ArvoredeDecisao.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1b-yZLjri5gyVTGNunE9FxTSXxU6h1gNW
"""

pip install plotly --upgrade

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px

"""**Fonte dos Dados**

[Fonte](https://www.kaggle.com/laotse/credit-risk-dataset)
"""

from google.colab import drive
drive.mount('/content/drive')

base_credito = pd.read_csv('/content/credit_risk_dataset.csv')

base_credito

base_credito.describe()

base_credito[base_credito['person_income'] >= 6000000]

"""**Visualização dos Dados**"""

base_credito[base_credito['loan_amnt'] <= 500.000000]

np.unique(base_credito['loan_status'], return_counts=True)

sns.countplot(x = base_credito['loan_status']);

plt.hist(x = base_credito['person_age']);

grafico = px.scatter_matrix(base_credito, dimensions=['person_age', 'person_income', 'loan_amnt'], color= 'loan_status')

grafico.show()

"""**Tratamento de valores inconsistentes**"""

base_credito.loc[base_credito['person_age'] > 122]

base_credito.mean()

base_credito['person_age'].mean()

base_credito.loc[base_credito['person_age'] > 122, 'person_age'] = 27.73

base_credito.loc[base_credito['person_age'] > 122]

"""**Tratamento de Valores Faltantes**"""

base_credito.isnull().sum()

base_credito.loc[pd.isnull(base_credito['person_emp_length'])]

base_credito['person_emp_length'].fillna(base_credito['person_emp_length'].mean(), inplace = True)

base_credito.loc[pd.isnull(base_credito['person_emp_length'])]

base_credito.loc[pd.isnull(base_credito['loan_int_rate'])]

base_credito['loan_int_rate'].fillna(base_credito['loan_int_rate'].mean(), inplace = True)

base_credito.loc[pd.isnull(base_credito['loan_int_rate'])]

"""**Divisão entre previsores e classe**"""

x_credit = base_credito.iloc[:,0:2].values

x_credit

y_credit = base_credito.iloc[:, 8].values

y_credit

"""**Escalonamento dos valores**"""

x_credit

from sklearn.preprocessing import StandardScaler
scaler_credit = StandardScaler()
x_credit = scaler_credit.fit_transform(x_credit)

x_credit[:,0].min(), x_credit[:,1].min()

x_credit[:,0].max(), x_credit[:,1].max()

x_credit

"""**Divisão das bases de treinamento e teste**"""

from sklearn.model_selection import train_test_split

x_credit_treinamento, x_credit_teste, y_credit_treinamento, y_credit_teste = train_test_split(x_credit, y_credit, test_size = 0.25, random_state = 0)

x_credit_treinamento.shape

y_credit_treinamento.shape

x_credit_teste.shape, y_credit_teste.shape

"""**Salvando os dados já pre-processados**"""

import pickle

with open('credito.pkl', mode = 'wb') as f:
  pickle.dump([x_credit_treinamento, y_credit_treinamento, x_credit_teste, y_credit_teste], f)

"""**Árvore de Decisão**"""

from sklearn.tree import DecisionTreeClassifier

with open('credito.pkl', 'rb') as f:  
  x_credit_treinamento, y_credit_treinamento, x_credit_teste, y_credit_teste = pickle.load(f)

arvore_credito = DecisionTreeClassifier(criterion='entropy', random_state = 0)
arvore_credito.fit(x_credit_treinamento, y_credit_treinamento)

previsoes = arvore_credito.predict(x_credit_teste)
previsoes

y_credit_teste

from sklearn.metrics import accuracy_score, classification_report

accuracy_score(y_credit_teste, previsoes)

from yellowbrick.classifier import ConfusionMatrix
cm = ConfusionMatrix(arvore_credito)
cm.fit(x_credit_treinamento, y_credit_treinamento)
cm.score(x_credit_teste, y_credit_teste)

print(classification_report(y_credit_teste, previsoes))